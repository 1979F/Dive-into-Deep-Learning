{"cells":[{"source":"🐳🐳\n- 第一部分是PyTorch中有关Tensor的一些基本用法，因为之前并没有系统学习过PyTorch，所以现在看书的同时慢慢学习PyTorch的知识\n\n- 第二部分是原书的知识和一些自己的理解\n\n**张量 Tensor** \n\n张量包含了一个数据集合，这个数据集合就是原始值变形而来的，它可以是一个任何维度的数据。tensor的rank就是其维度。\n\nRank本意是矩阵的秩，不过Tensor Rank和Matrix Rank的意义不太一样，这里就还叫Rank。Tensor Rank的意义看起来更像是维度，比如Rank =1就是向量，Rank=2 就是矩阵了，Rank = 0 就是一个值。\n","cell_type":"markdown","metadata":{"trusted":true,"collapsed":false,"jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"id":"179B88EB648B47978081EA002A1EC852","mdEditEnable":false}},{"metadata":{"id":"A2ED9B829E354484803F7E522FA523B6","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"## 一、PyTorch 中的Tensor\n在PyTorch中，**` torch.Tensor `**是存储和变换数据的主要工具。`Tensor` 和 `NumPy` 的多维数组非常类似。"},{"metadata":{"id":"771B93AA6F5B48CC80491554646B98C2","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"首先导入PyTorch"},{"metadata":{"id":"219D571EE6E947D58B537E16BCEC7D73","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"import torch","execution_count":29},{"metadata":{"id":"8F9F72CEC71F4B9787D385DF43C101DF","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"### 1.1 Tensor的创建"},{"metadata":{"id":"A39B2E7317AD47F68F65E82CFDC4911A","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"创建一个5x3的未初始化的 `Tensor`"},{"metadata":{"id":"09E41200954141E389599C5BD1A02315","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"tensor([[5.4880e+23, 4.5886e-41, 2.7434e-24],\n        [3.0915e-41, 4.4842e-44, 0.0000e+00],\n        [4.4842e-44, 0.0000e+00, 2.7450e-24],\n        [3.0915e-41, 5.4880e+23, 4.5886e-41],\n        [4.2039e-45, 0.0000e+00, 4.6243e-44]])\n","name":"stdout"}],"source":"x = torch.empty(5, 3)\nprint(x)","execution_count":30},{"metadata":{"id":"5E66219AA234409C8CCFEE135A9727CA","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"创建一个5x3的随机初始化的 `Tensor`"},{"metadata":{"id":"9F653A705842427C890FB587491F090E","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"tensor([[0.7787, 0.8019, 0.3431],\n        [0.1335, 0.3062, 0.2305],\n        [0.6151, 0.5777, 0.2794],\n        [0.4701, 0.6086, 0.9624],\n        [0.6524, 0.6794, 0.8206]])\n","name":"stdout"}],"source":"x = torch.rand(5, 3)  # 这里rand的用法后面会讲到\nprint(x)","execution_count":31},{"metadata":{"id":"20CA841BBB7C4D2386658B1AE68D943B","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"创建一个5x3的long类型全0的 `Tensor`"},{"metadata":{"id":"382FD298CD3D47848DD34019C838C8EB","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"tensor([[0, 0, 0],\n        [0, 0, 0],\n        [0, 0, 0],\n        [0, 0, 0],\n        [0, 0, 0]])\n","name":"stdout"}],"source":"x = torch.zeros(5, 3, dtype=torch.long)\nprint(x)","execution_count":32},{"metadata":{"id":"05155485D003403B81EEF73780C26B65","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"直接根据数据创建"},{"metadata":{"id":"60FC0C0E96354C5C8F561740119E656C","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"tensor([5.5000, 3.0000])\n","name":"stdout"}],"source":"x = torch.tensor([5.5, 3])\nprint(x)","execution_count":33},{"metadata":{"id":"6290C4330C0B4EC489D9356D7EC76683","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"通过现有的 `Tensor` 来创建，此方法会默认重用输入 `Tensor` 的一些属性，例如数据类型，除非自定义数据类型。"},{"metadata":{"id":"497F018AF5594FC08C2F574C142CE825","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"tensor([[1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.],\n        [1., 1., 1.]], dtype=torch.float64)\ntensor([[-0.9532,  0.4367, -0.1972],\n        [ 2.1078,  0.3750, -0.2939],\n        [-0.3682,  1.3246, -0.7197],\n        [-0.4119,  0.2093, -0.3431],\n        [-1.7094,  0.0638, -0.4597]])\n","name":"stdout"}],"source":"x = x.new_ones(5, 3, dtype=torch.float64)  # new_ones 返回一个与size大小相同的用1填充的张量,默认具有相同的torch.dtype和torch.device\nprint(x)\n\nx = torch.randn_like(x, dtype=torch.float) # randn_like形状与输入的张量相同，指定新的数据类型\nprint(x) ","execution_count":36},{"metadata":{"id":"F07885262597410F8142C42F3DAC73B6","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"通过 `shape` 或者` size()` 来获取 `Tensor` 的形状"},{"metadata":{"id":"A51BF50B07EE4493818F7A7C0A6AE1F1","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"torch.Size([5, 3])\ntorch.Size([5, 3])\n","name":"stdout"}],"source":"print(x.size())\nprint(x.shape)","execution_count":35},{"metadata":{"id":"DE805C4801DC4BC78E4B54771E4C0D1C","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":true},"cell_type":"markdown","source":"✨ 注意：返回的torch.Size其实就是一个tuple, 支持所有tuple的操作。"},{"metadata":{"id":"9B8F5822099C49E1895E979A00AE1901","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"### 1.2 Tensor的数据类型"},{"metadata":{"id":"92E7FB296B0C4FA28E3F5AB5DB3787E4","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"#### 1.2.1  torch.FloatTensor\n此变量用于生成数据类型为浮点型的 `Tensor`，传递给 `torch.FloatTensor` 的参数可以是一个列表，也可以是一个维度值。"},{"metadata":{"id":"24B9399DE8984C728BEDE1E602CE4538","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"tensor([[5.4880e+23, 4.5886e-41, 5.4880e+23],\n        [4.5886e-41, 1.4584e-19, 7.8458e+17]])\n","name":"stdout"}],"source":"a = torch.FloatTensor(2, 3)  # 两行三列\nprint(a)","execution_count":1},{"metadata":{"id":"B25BCD44384447DF9E6B36B276BB4979","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"tensor([[2., 3.],\n        [4., 5.]]) torch.Size([2, 2]) torch.float32\n","name":"stdout"}],"source":"b = torch.FloatTensor([[2, 3], [4, 5]])\nprint(b, b.shape, b.dtype)","execution_count":6},{"metadata":{"id":"C3D743C9DC134204A1C51486C3B3D864","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"#### 1.2.2 torch.IntTensor\n\n用于生成数据类型为整型的 `Tensor`，传递给 `torch.IntTensor` 的参数可以是一个列表，也可以是一个维度值。"},{"metadata":{"id":"5DD82BD9311846C8891E246A3B008EE2","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"tensor([[1726508320,      32745,  407958368],\n        [     22062, 1953384789, 1701869908]], dtype=torch.int32)\n","name":"stdout"}],"source":"a = torch.IntTensor(2, 3)\nprint(a)","execution_count":8},{"metadata":{"id":"33F065951F9147B583E65F7DA339E9DE","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"tensor([[2, 3],\n        [4, 5]], dtype=torch.int32) torch.int32\n","name":"stdout"}],"source":"b = torch.IntTensor([[2, 3], [4, 5]])\nprint(b, b.dtype)","execution_count":10},{"metadata":{"id":"39B58D2B06474583BE352732AC1D89EE","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"#### 1.2.3 torch.rand\n \n用于生成数据类型为**浮点型**且维度指定的随机 `Tensor`，和在 `Numpy` 中使用 `numpy.rand` 生成随机数的方法类似，随机生成的浮点数据在 **0~1区间均匀分布。**"},{"metadata":{"id":"7AEBBDE18A674A05A76D11DDC4B9EC9E","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"tensor([[0.8055, 0.3392, 0.5802],\n        [0.3333, 0.7156, 0.3415]]) torch.float32\n","name":"stdout"}],"source":"a = torch.rand(2, 3)\nprint(a, a.dtype)","execution_count":14},{"metadata":{"id":"4587178549B44400B691D7EF8273D9D1","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"#### 1.2.4 torch.randn\n\n用于生成数据类型为**浮点型**且维度指定的随机 `Tensor`，和在 `Numpy` 中使用 `numpy.randn `生成随机数的方法类似，随机生成的浮点数的取值满足**均值为0，方差为1的正态分布**。"},{"metadata":{"id":"C84341663F7F42DD938BA8EBCEFCA2A8","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"tensor([[ 0.4737,  0.3686, -1.1102],\n        [ 0.9147, -0.3446, -0.7511]]) torch.float32\n","name":"stdout"}],"source":"a = torch.randn(2, 3)\nprint(a, a.dtype)","execution_count":13},{"metadata":{"id":"B12A7A01FA1D4DF3B951442867823B7E","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"#### 1.2.5 torch.range\n\n用于生成数据类型为**浮点型**且自定义其实范围和结束范围的 `Tensor`，所以传递给 `torch.range` 的参数有三个，分别是范围的**起始值**，范围的**结束值**和**步长**，其中，步长用于指定从起始值到结束值的每步的数据间隔。"},{"metadata":{"id":"0364C4675AB3453493C647F6DE604994","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"tensor([2., 5., 8.]) torch.float32\n","name":"stdout"},{"output_type":"stream","text":"/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: UserWarning: torch.range is deprecated in favor of torch.arange and will be removed in 0.5. Note that arange generates values in [start; end), not [start; end].\n  \n","name":"stderr"}],"source":"a = torch.range(2, 8, 3)\nprint(a, a.dtype)","execution_count":18},{"metadata":{"id":"387EB7CE46004E469535C9F587E577AC","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"#### 1.2.6 torch.zeros\n\n用于生成数据类型为**浮点型**且维度指定的 `Tensor`，不过这个浮点型的 `Tensor` 中的元素值全部为0"},{"metadata":{"id":"B67996BFFED94DB38AB43E4502399AD3","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"tensor([[0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.]]) torch.float32\n","name":"stdout"}],"source":"a = torch.zeros(3, 4)\nprint(a, a.dtype)","execution_count":19},{"metadata":{"id":"9269C72874974FB39403F0A89E804543","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"### 1.3 Tensor的运算\n\n这里通常对 `Tensor` 数据类型的变量进行运算，来组合一些简单或者复杂的算法，常用的 `Tensor` 运算如下："},{"metadata":{"id":"91D0C9DF071643398356B97B61651EE8","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"#### 1.3.1 torch.abs\n\n将参数传递到 `torch.abs` 后返回输入参数的绝对值作为输出，输出参数必须是一个 `Tensor` 数据类型的变量"},{"metadata":{"id":"7063170F6C30481785D4904F2C381671","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"tensor([[-1.5257,  0.1174, -0.2927],\n        [ 0.4662,  0.7019,  0.2605]])\ntensor([[1.5257, 0.1174, 0.2927],\n        [0.4662, 0.7019, 0.2605]])\n","name":"stdout"}],"source":"a = torch.randn(2, 3)\nprint(a)\nb = torch.abs(a)\nprint(b)","execution_count":20},{"metadata":{"id":"FFE5F16B7176430BAA597309EAB60F75","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"#### 1.3.2 torch.add\n将参数传递到 `torch.add` 后返回输入参数的求和结果作为输出，输入参数既可以全部是 `Tensor` 数据类型的变量，也可以是一个 `Tensor` 数据类型的变量，另一个是标量。"},{"metadata":{"id":"69A2EC3E932F49E39D2A2C67FA7B0C9F","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"tensor([[-1.5090, -1.1659, -0.7795],\n        [ 0.8453, -0.0334,  0.2251]])\ntensor([[-1.5168, -1.2602,  0.8775],\n        [ 1.8206, -0.0880, -1.1371]])\ntensor([[-3.0258, -2.4261,  0.0980],\n        [ 2.6659, -0.1213, -0.9120]])\ntensor([[0.2818, 1.4852, 2.0287],\n        [1.1209, 1.6720, 1.0154]])\ntensor([[10.2818, 11.4852, 12.0287],\n        [11.1209, 11.6720, 11.0154]])\n","name":"stdout"}],"source":"a = torch.randn(2, 3)\nprint(a)\n\nb = torch.randn(2, 3)\nprint(b)\n\nc = torch.add(a, b)\nprint(c)\n\nd = torch.randn(2, 3)\nprint(d)\n\ne = torch.add(d, 10)\nprint(e)","execution_count":38},{"metadata":{"id":"2537D38C74FB4DD68745CE9EEA803E21","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"可以指定输出"},{"metadata":{"id":"A9ED51FF23474A80A72ED031C36BC37C","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"tensor([[-3.0258, -2.4261,  0.0980],\n        [ 2.6659, -0.1213, -0.9120]])\n","name":"stdout"}],"source":"result = torch.empty(2, 3)\ntorch.add(a, b, out=result)\nprint(result)","execution_count":40},{"metadata":{"id":"448EF3C0B0934C2288E26D2E9479C6FF","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"关于加法还有两种方式：\n- 第一种，+号\n- 第二种，inplace\n\n✨ 注：PyTorch操作inplace版本都有后缀_, 例如x.copy_(y), x.t_()"},{"metadata":{"id":"DB2F3D0AE76C49168F4D66137A53049C","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"tensor([[-3.0258, -2.4261,  0.0980],\n        [ 2.6659, -0.1213, -0.9120]])\n","name":"stdout"}],"source":"print(a+b)","execution_count":41},{"metadata":{"id":"BB501B3CBBB940D1B4C74C287BE0D109","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"tensor([[-3.0258, -2.4261,  0.0980],\n        [ 2.6659, -0.1213, -0.9120]])\n","name":"stdout"}],"source":"b.add_(a)\nprint(b)","execution_count":42},{"metadata":{"id":"F693F97B1C6144648DCA50827D8EB830","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"#### 1.3.3 torch.clamp\n　　\n       对输入参数按照自定义的范围进行裁剪，最后将参数裁剪的结果作为输出。所以输入参数一共有三个，分别是需要进行裁剪的**Tensor数据类型的变量**、**裁剪的上边界**和**裁剪的下边界**，\n\t\t\t \n具体的裁剪过程是：使用变量中的每个元素分别和裁剪的上边界及裁剪的下边界的值进行比较，如果元素的值小于裁剪的下边界的值，该元素就被重写成裁剪的下边界的值；\n\n同理，如果元素的值大于裁剪的上边界的值，该元素就被重写成裁剪的上边界的值。"},{"metadata":{"id":"71D6ECC57E8E46FEAD50A97EB1AF0E31","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"tensor([[ 0.5965,  2.1073, -1.2866],\n        [-0.1101, -1.6736, -2.2357]])\ntensor([[ 0.1000,  0.1000, -0.1000],\n        [-0.1000, -0.1000, -0.1000]])\n","name":"stdout"}],"source":"a = torch.randn(2, 3)\nprint(a)\n\nb = torch.clamp(a, -0.1, 0.1)\nprint(b)","execution_count":23},{"metadata":{"id":"DFC6C1E7A84A4EE9BD57F16B12A67BFA","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"#### 1.3.4 torch.div\n\n将参数传递到 `torch.div` 后返回输入参数的求商结果作为输出，同样，参与运算的参数可以全部是 `Tensor` 数据类型的变量，也可以是 `Tensor` 数据类型的变量和标量的组合。"},{"metadata":{"id":"71BAEC637FBB4D44A57AD06E8FAA7CD0","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"tensor([[ 0.4518,  0.1334,  1.7579],\n        [ 0.0349, -0.2346,  1.6790]])\ntensor([[ 1.2516, -1.1198,  1.1351],\n        [-0.6222, -0.6472, -0.0758]])\ntensor([[  0.3610,  -0.1191,   1.5486],\n        [ -0.0561,   0.3624, -22.1492]])\ntensor([[ 0.2908,  0.0664, -1.4821],\n        [ 0.4358,  0.3226,  1.0338]])\ntensor([[ 0.0291,  0.0066, -0.1482],\n        [ 0.0436,  0.0323,  0.1034]])\n","name":"stdout"}],"source":"a = torch.randn(2,3)\nprint(a)\n \nb = torch.randn(2,3)\nprint(b)\n \nc = torch.div(a,b)\nprint(c)\n \nd = torch.randn(2,3)\nprint(d)\n \ne = torch.div(d,10)\nprint(e)","execution_count":24},{"metadata":{"id":"AD7D508B1447494E8AC406F8E6BB287D","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"#### 1.3.5 torch.mul\n\n将参数传递到 `torch.mul` 后返回输入参数求积的结果作为输出，参与运算的参数可以全部是 `Tensor` 数据类型的变量，也可以是 `Tensor` 数据类型的变量和标量的组合。"},{"metadata":{"id":"2347304973C2428BAF66E3431CBEE372","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"tensor([[ 0.5851,  0.2113,  0.6891],\n        [ 1.1177, -0.0177,  1.5595]])\ntensor([[ 0.9094, -0.0707, -0.3900],\n        [ 0.2990, -0.9827,  0.7165]])\ntensor([[ 0.5321, -0.0149, -0.2687],\n        [ 0.3342,  0.0174,  1.1174]])\ntensor([[-0.7012,  1.2348,  1.6156],\n        [ 0.5412,  0.2345, -0.5753]])\ntensor([[-7.0115, 12.3478, 16.1558],\n        [ 5.4116,  2.3447, -5.7526]])\n","name":"stdout"}],"source":"a = torch.randn(2, 3)\nprint(a)\n\nb = torch.randn(2, 3)\nprint(b)\n\nc = torch.mul(a, b)\nprint(c)\n\nd = torch.randn(2, 3)\nprint(d)\n\ne = torch.mul(d, 10)\nprint(e)","execution_count":25},{"metadata":{"id":"6F7056934CE948BA822F7FE8409F51D5","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"#### 1.3.6 torch.pow\n\n将参数传递到 `torch.pow` 后返回输入参数的求幂结果作为输出，参与运算的参数可以全部是 `Tensor` 数据类型的变量，也可以是 `Tensor` 数据类型的变量和标量的组合。"},{"metadata":{"id":"3999A9C49E9F49458686614DD8BD0F44","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"tensor([[-0.9387,  1.0499, -1.6718],\n        [-0.3190, -1.1677, -0.0666]])\ntensor([[0.8812, 1.1024, 2.7948],\n        [0.1018, 1.3635, 0.0044]])\n","name":"stdout"}],"source":"a = torch.randn(2, 3)\nprint(a)\n\nb = torch.pow(a, 2)\nprint(b)","execution_count":26},{"metadata":{"id":"75EB59E03EC54996827CEB4BDFBD1972","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"#### 1.3.7 torch.mm\n\n将参数传递到 `torch.mm` 后返回输入参数的求积结果作为输出，不过这个求积的方式和之前的 `torch.mul `运算方式不太样，\n\n`torch.mm` 运用矩阵之间的乘法规则进行计算，所以被传入的参数会被当作矩阵进行处理，参数的维度自然也要满足矩阵乘法的前提条件，\n\n即**前一个矩阵的行数必须和后一个矩阵的列数相等**，否则不能进行计算。"},{"metadata":{"id":"12BDEB9889A149E28209C3717A0B7407","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"tensor([[ 0.1701,  0.9539, -0.3128],\n        [-0.2466,  2.4600, -1.6023]])\ntensor([[-1.0573, -1.0292],\n        [-0.2707,  0.2992],\n        [-1.0913, -3.1058]])\ntensor([[-0.0967,  1.0818],\n        [ 1.3436,  5.9664]])\n","name":"stdout"}],"source":"a = torch.randn(2, 3)\nprint(a)\n\nb = torch.randn(3, 2)\nprint(b)\n\nb = torch.mm(a, b)\nprint(b)","execution_count":27},{"metadata":{"id":"35E609DCCABB4300893661DA7C4344C0","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"#### 1.3.8 torch.mv\n将参数传递到 `torch.mv` 后返回输入参数的求积结果作为输出，`torch.mv` 运用矩阵与向量之间的乘法规则进行计算，被传入的参数中的第1个参数代表矩阵，第2个参数代表向量，顺序不能颠倒。"},{"metadata":{"id":"14287915DA394EF797D66FE38B14A869","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"tensor([[ 1.7745,  0.8665, -0.5622],\n        [-0.6072,  0.5540, -1.0647]])\ntensor([ 0.0553, -0.5526, -1.0924])\ntensor([0.2335, 0.8233])\n","name":"stdout"}],"source":"a = torch.randn(2, 3)\nprint(a)\n\nb = torch.randn(3)\nprint(b)\n\nc = torch.mv(a, b)\nprint(c)","execution_count":28},{"metadata":{"id":"35C7319C388440698BFDF28F558F3026","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"## 二、原书"},{"metadata":{"id":"8651DBDE538C4812876FCD138878CC67","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":" ### 2.1 数据操作\n 部分操作已经在前面提及"},{"metadata":{"id":"7466AC39FB56435688C94FB8F38906FD","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"#### 2.1.1 索引\n索引出来的结果与原数据共享内存，也即修改一个，另一个会跟着修改。"},{"metadata":{"id":"E307BD4D59574DEB8D13F6148A59BB42","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"tensor([[ 0.5706,  0.3683,  1.4869,  1.2791],\n        [-0.1592, -1.7226, -1.1192, -0.9729]])\ntensor([[ 0.5706,  0.3683,  1.4869],\n        [-0.1592, -1.7226, -1.1192]])\ntensor([[ 1.5706,  1.3683,  2.4869],\n        [ 0.8408, -0.7226, -0.1192]])\ntensor([[ 1.5706,  1.3683,  2.4869],\n        [ 0.8408, -0.7226, -0.1192]])\ntensor([[ 1.5706,  1.3683,  2.4869,  1.2791],\n        [ 0.8408, -0.7226, -0.1192, -0.9729]])\n","name":"stdout"}],"source":"x = torch.randn(2, 4)\nprint(x)\ny = x[:, :3]\nprint(y)\ny += 1\nprint(y)\nprint(x[:, :3]) # 源tensor也被改了\nprint(x)","execution_count":47},{"metadata":{"id":"573E5E328A2D435C84DE6C487D8F4280","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"除了常用的索引选择数据之外，PyTorch还提供了一些高级的选择函数:"},{"metadata":{"id":"B80EE288BA7044B694CA7B8FC54BE0FD","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"| 函数      | 功能 |\n| :---        |    :----:   |\n| index_select(input, dim, index)      | 在指定维度dim上选取，比如选取某些行、某些列       | \n| masked_select(input, mask,out=None)   | 根据布尔掩码 (boolean mask) 索引输入张量的 1D 张量        | \n|nonzero(input)   | 非0元素的下标 |\n|gather(input, dim, index)\t|  根据index，在dim维度上选取数据，输出的size与index一样|"},{"metadata":{"id":"6DA4DC6F9E174FFBAAAE36B66E912906","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"**index_select**\n```\nindex_select(\n    input,\n    dim,\n    index\n)\n```\n\n参数：\n- input：索引的对象\n- dim：表示从第几维挑选数据，类型为int值；**0表示按行索引，1表示按列索引**\n- index：表示从第一个参数维度中的哪个位置挑选数据，类型为torch.Tensor类的实例；"},{"metadata":{"id":"4999700858AC42FB8801E3B757925843","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"tensor([[ 1.5706,  1.3683,  2.4869,  1.2791],\n        [ 0.8408, -0.7226, -0.1192, -0.9729]])\ntensor([[ 1.5706,  1.3683],\n        [ 0.8408, -0.7226]])\n","name":"stdout"}],"source":"print(torch.index_select(x,0,torch.tensor([0, 1])))\nprint(torch.index_select(x,1,torch.tensor([0, 1])))","execution_count":53},{"metadata":{"id":"63689DFBCFE948B18F623818A2C0D670","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"**masked_select**\n\n```\nmasked_select(\n    input,\n    mask,\n    out\n)\n```\n\n参数：\n- input(Tensor) ：需要进行索引操作的输入张量；\n- mask(BoolTensor) ：要进行索引的布尔掩码\n- out(Tensor, optional) ：指定输出的张量。比如执行 torch.zeros([2, 2], out = tensor_a)，相当于执行 tensor_a = torch.zeros([2, 2])；\n\n⚠️ **注意：「** masked_select 函数最关键的参数就是布尔掩码 mask，\n\n传入 mask 参数的布尔张量通过 True 和 False (或 1 和 0) 来决定输入张量对应位置的元素是否保留，\n\n既然是一一对应的关系，这就需要传入 mask 中的布尔张量和传入 input 中的输入张量形状要相同。**」**"},{"metadata":{"id":"1A2BC6B8092B404C8BF09A90DF80E645","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"tensor([[ True,  True,  True,  True],\n        [ True, False, False, False]])\ntensor([1.5706, 1.3683, 2.4869, 1.2791, 0.8408])\n","name":"stdout"}],"source":"mask = x.ge(0.5)\nprint(mask)\nprint(torch.masked_select(x, mask))","execution_count":56},{"metadata":{"id":"5A48035FC68B4A73A5566FE975BC4196","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"tensor([[ 1.5706,  1.3683,  2.4869,  1.2791],\n        [ 0.8408, -0.7226, -0.1192, -0.9729]])\ntensor([[0, 0],\n        [0, 1],\n        [0, 2],\n        [0, 3],\n        [1, 0],\n        [1, 1],\n        [1, 2],\n        [1, 3]])\n","name":"stdout"}],"source":"print(x)\nprint(torch.nonzero(x))","execution_count":55},{"metadata":{"id":"F2A37A073F184F2BB667069442E8A774","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"**gather**\n\n```\ngather(\n    input, \n    dim,\n    index\n)\n```\n\n\n参数：\n- input (Tensor) – 需要进行索引操作的输入张量；\n- dim (int) – 表示从第几维挑选数据，类型为int值；\n- index (LongTensor) – 要收集的元素的索引；\n- out (Tensor, optional) – 指定输出的张量。"},{"metadata":{"id":"703A983CBD7C45D1B147EBBE5AE33AF9","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"tensor([[1.5706, 1.3683],\n        [0.8408, 0.8408]])\ntensor([[ 1.5706, -0.7226, -0.1192,  1.2791],\n        [ 1.5706,  1.3683,  2.4869,  1.2791]])\n","name":"stdout"}],"source":"print(torch.gather(x, dim=1, index=torch.LongTensor([[0, 1],[0, 0]])))  # dim为1说明按列索引，[0, 1]表示第一行的第0列和第1列，就是1.5706和1.3683，同理[0, 0]是0.8408和0.8408\nprint(torch.gather(x, dim=0, index=torch.LongTensor([[0,1,1,0],[0,0,0,0]])))   # dim为0说明按行索引，[0, 1, 1, 0]表示第0行，第1行，第1行，第0行","execution_count":67},{"metadata":{"id":"DC05D38D828543C8876719633F6C8183","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"#### 2.1.2 改变形状"},{"metadata":{"id":"00533389C49F4C0AA3C3986759461217","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"用 `view()` 来改变 `Tensor` 的形状：\n\n⚠️ 需要注意的是：-1所指的维度可以根据其他维度的值推出来，这个用法在很多地方都见过，应该要记住"},{"metadata":{"id":"1EA671E134744CB8B445BD35673A9972","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"torch.Size([2, 4]) torch.Size([8]) torch.Size([4, 2])\n","name":"stdout"}],"source":"y = x.view(8)\nz = x.view(-1, 2)  # -1所指的维度可以根据其他维度的值推出来\nprint(x.size(), y.size(), z.size())","execution_count":71},{"metadata":{"id":"079DA87AE172488E87B2FFA632BDFE05","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"🔥 `view() `返回的新 `Tensor` 与源 `Tensor` 虽然可能有不同的 `size`，但是是共享 `data` 的，也即更改其中的一个，另外一个也会跟着改变。(顾名思义，`view` 仅仅是改变了对这个张量的观察角度，内部数据并未改变)"},{"metadata":{"id":"1A63393F477F43D9BCBC4A5BF83BBA18","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"tensor([[2.5706, 2.3683, 3.4869, 2.2791],\n        [1.8408, 0.2774, 0.8808, 0.0271]])\ntensor([2.5706, 2.3683, 3.4869, 2.2791, 1.8408, 0.2774, 0.8808, 0.0271])\n","name":"stdout"}],"source":"x += 1\nprint(x)\nprint(y)","execution_count":72},{"metadata":{"id":"E5915DB1C4B14F4CB6171ABCB8F8A9E5","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"所以如果我们想返回一个真正新的副本（即不共享data内存）该怎么办呢？\n\nPytorch还提供了一个 `reshape()` 可以改变形状，但是此函数并不能保证返回的是其拷贝，所以不推荐使用。推荐先用 `clone` 创造一个副本然后再使用 `view`。"},{"metadata":{"id":"021812C7F6F04C1B94D73F874292ED06","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"tensor([[ 1.5706,  1.3683,  2.4869,  1.2791],\n        [ 0.8408, -0.7226, -0.1192, -0.9729]])\ntensor([2.5706, 2.3683, 3.4869, 2.2791, 1.8408, 0.2774, 0.8808, 0.0271])\n","name":"stdout"}],"source":"x_cp = x.clone().view(8)\nx -= 1\nprint(x)\nprint(x_cp)","execution_count":73},{"metadata":{"id":"D63078BB8AC4462983534AEFAA08BA33","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"✨ 使用 `clone` 还有一个好处是会被记录在计算图中，即梯度回传到副本时也会传到源 `Tensor`\n\n另外一个常用的函数就是 `item() `, 它可以将一个标量 `Tensor` 转换成一个Python number："},{"metadata":{"id":"B465CA58F42A4B5888A03ADB7093027D","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"tensor([1.0600])\n1.059958815574646\n","name":"stdout"}],"source":"x = torch.randn(1)\nprint(x)\nprint(x.item())","execution_count":74},{"metadata":{"id":"E01C34106B3D46C9BD841F5C41F4CF4C","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"#### 2.1.3 线性代数\n\n另外，PyTorch还支持一些线性函数，这里提一下，免得用起来的时候自己造轮子，具体用法参考官方文档。如下表所示：\n\n| 函数      | 功能 | \n| :---        |    :----:   |\n| trace      | 对角线元素之和(矩阵的迹)       | \n| diag   | 对角线元素        |\n|triu/tril | 矩阵的上三角/下三角，可指定偏移量 |\n|mm/bmm | 矩阵乘法，batch的矩阵乘法|\n|addmm/addbmm/addmv/addr/baddbmm..\t |矩阵运算 |\n|t |转置 |\n|dot/cross | 内积/外积|\n|inverse  | 求逆矩阵|\n|svd | 奇异值分解|"},{"metadata":{"id":"755F0F24D13B4F5286654F4445B2CD29","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"### 2.1.4 广播机制\n\n当对两个形状不同的 `Tensor` 按元素运算时，可能会触发广播（broadcasting）机制：先适当复制元素使这两个 `Tensor` 形状相同后再按元素运算。"},{"metadata":{"id":"C358EB44EAD942ED931251F2DCF6BCFA","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"tensor([[1, 2]])\ntensor([[1],\n        [2],\n        [3]])\ntensor([[2, 3],\n        [3, 4],\n        [4, 5]])\n","name":"stdout"}],"source":"x = torch.arange(1, 3).view(1, 2)\nprint(x)\ny = torch.arange(1, 4).view(3, 1)\nprint(y)\nprint(x + y)","execution_count":75},{"metadata":{"id":"7D7CE72F1CB24B9DB7886E7E3FA7EEEF","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"由于 `x` 和 `y` 分别是1行2列和3行1列的矩阵，如果要计算 `x + y`，那么 `x` 中第一行的2个元素被广播（复制）到了第二行和第三行，\n\n而 `y` 中第一列的3个元素被广播（复制）到了第二列。如此，就可以对2个3行2列的矩阵按元素相加。"},{"metadata":{"id":"B32F654454634E228B736612BD474672","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"### 2.1.5 运算内存开销\n\n前面说了，索引操作是不会开辟新内存的，而像` y = x + y` 这样的运算是会新开内存的，然后将y指向新内存。\n\n为了演示这一点，我们可以使用Python自带的 `id` 函数：如果两个实例的ID一致，那么它们所对应的内存地址相同；反之则不同。"},{"metadata":{"id":"DFD35EF4110E4E9A86D2CAB6C5F6E684","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"False\n","name":"stdout"}],"source":"x = torch.tensor([1, 2])\ny = torch.tensor([3, 4])\nid_before = id(y)\ny = y + x\nprint(id(y) == id_before) # False ","execution_count":76},{"metadata":{"id":"3783CB06BD944DB894D42D9764B81056","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"如果想指定结果到原来的 `y` 的内存，我们可以使用前面介绍的索引来进行替换操作。在下面的例子中，我们把` x + y `的结果通过 `[:]` 写进 `y` 对应的内存中。"},{"metadata":{"id":"F2E30B325E8541B285696F5FD9EE2446","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"True\n","name":"stdout"}],"source":"x = torch.tensor([1, 2])\ny = torch.tensor([3, 4])\nid_before = id(y)\ny[:] = y + x\nprint(id(y) == id_before) # True","execution_count":77},{"metadata":{"id":"CA8D50F7B93044FE80B64DD9878CA999","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"我们还可以使用运算符全名函数中的 `out` 参数或者自加运算符 `+=` (也即 `add_()` )达到上述效果，例如 `torch.add(x, y, out=y) `和 `y += x(y.add_(x))`。"},{"metadata":{"id":"AFCC6759D4E44F11BDB0AF2C469C1756","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"True\n","name":"stdout"}],"source":"x = torch.tensor([1, 2])\ny = torch.tensor([3, 4])\nid_before = id(y)\ntorch.add(x, y, out=y) # y += x, y.add_(x)\nprint(id(y) == id_before) # True","execution_count":78},{"metadata":{"id":"5D1DF6518622439E88F16CEFB09A328E","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"✨ 注：虽然 `view` 返回的 `Tensor` 与源 `Tensor` 是共享data的，但是依然是一个新的 `Tensor`（因为 `Tensor` 除了包含data外还有一些其他属性），二者id（内存地址）并不一致。"},{"metadata":{"id":"D0F4B77C6ADC485487CD563EE26BD680","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"### 2.1.6 Tensor和NumPy相互转换"},{"metadata":{"id":"9E6A4F7444D44B408CD1E5D6CB9DF5E3","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"我们很容易用 `numpy()` 和 `from_numpy()` 将 `Tensor` 和 `NumPy` 中的数组相互转换。\n\n但是需要注意的一点是： **这两个函数所产生的的 `Tensor` 和 `NumPy` 中的数组共享相同的内存（所以他们之间的转换很快），改变其中一个时另一个也会改变！！！**\n\n✨ **还有一个常用的将NumPy中的array转换成Tensor的方法就是torch.tensor(), 需要注意的是，此方法总是会进行数据拷贝（就会消耗更多的时间和空间），所以返回的Tensor和原来的数据不再共享内存。**"},{"metadata":{"id":"43600BDC14484E55822C3D360F83A148","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"**Tensor转NumPy**\n\n使用 `numpy() `将 `Tensor` 转换成 `NumPy` 数组:"},{"metadata":{"id":"23C150F46FEE44138D3EAB592875EE40","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"tensor([1., 1., 1., 1., 1.]) [1. 1. 1. 1. 1.]\ntensor([2., 2., 2., 2., 2.]) [2. 2. 2. 2. 2.]\ntensor([3., 3., 3., 3., 3.]) [3. 3. 3. 3. 3.]\n","name":"stdout"}],"source":"a = torch.ones(5)\nb = a.numpy()\nprint(a, b)\n\na += 1\nprint(a, b)\nb += 1\nprint(a, b)","execution_count":79},{"metadata":{"id":"214CA8B38B624FD9ACCC858A0A8E1932","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"**NumPy数组转Tensor**\n\n使用` from_numpy()` 将 `NumPy` 数组转换成 `Tensor` :"},{"metadata":{"id":"88F5411CDEC04C1F88FFDCD138CCB1D6","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"[1. 1. 1. 1. 1.] tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n[2. 2. 2. 2. 2.] tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n[3. 3. 3. 3. 3.] tensor([3., 3., 3., 3., 3.], dtype=torch.float64)\n","name":"stdout"}],"source":"import numpy as np\na = np.ones(5)\nb = torch.from_numpy(a)\nprint(a, b)\n\na += 1\nprint(a, b)\nb += 1\nprint(a, b)","execution_count":80},{"metadata":{"id":"32BDA5349371431E82B47DD88E6A0154","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"所有在CPU上的 `Tensor`（除了 `CharTensor`）都支持与 `NumPy` 数组相互转换。\n\n此外上面提到还有一个常用的方法就是直接用 `torch.tensor() `将 `NumPy` 数组转换成 `Tensor`，\n\n需要注意的是该方法总是会进行数据拷贝，返回的 `Tensor` 和原来的数据不再共享内存。"},{"metadata":{"id":"D5B4DC31F5B74DE88A9EBDE843F2B71F","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[{"output_type":"stream","text":"[4. 4. 4. 4. 4.] tensor([3., 3., 3., 3., 3.], dtype=torch.float64)\n","name":"stdout"}],"source":"c = torch.tensor(a)\na += 1\nprint(a, c)","execution_count":81},{"metadata":{"id":"D3791AA89A534D3389ADDEB8D0767CDC","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"### 2.1.7 Tensor on GPU\n\n用方法 `to()` 可以将 `Tensor` 在CPU和GPU（需要硬件支持）之间相互移动。"},{"metadata":{"id":"5D98874A972D4FE1A774C6470B5AD8AD","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"collapsed":false,"scrolled":false},"cell_type":"code","outputs":[],"source":"# 以下代码只有在PyTorch GPU版本上才会执行\nif torch.cuda.is_available():\n    device = torch.device(\"cuda\")          # GPU\n    y = torch.ones_like(x, device=device)  # 直接创建一个在GPU上的Tensor\n    x = x.to(device)                       # 等价于 .to(\"cuda\")\n    z = x + y\n    print(z)\n    print(z.to(\"cpu\", torch.double))       # to()还可以同时更改数据类型","execution_count":82},{"metadata":{"id":"5AA8DBAD8A634CDFB66ECEBCEFB22BA6","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":false},"cell_type":"markdown","source":"### 2.2 自动求梯度\n\n在深度学习中，我们经常需要对函数求梯度（gradient）。\n\nPyTorch提供的 **autograd** 包能够根据输入和前向传播过程自动构建计算图，并执行反向传播。本节将介绍如何使用autograd包来进行自动求梯度的有关操作。"},{"metadata":{"id":"9A4C91FECA6740D4A713CB7A3AC414D7","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true,"mdEditEnable":true},"cell_type":"markdown","source":"#### 2.2.1 概念\n\nTesnor 是 autograd 包的核心，如果将其属性 `.requires_grad` 设置为 `True`，它将开始追踪在其上的所有操作（这样就可以利用**链式法则**进行梯度传播了）。\n\n完成计算后，可以调用 `.backward( ) `来完成所有梯度计算。此 Tensor 的梯度将累积到 `.grad` 属性中。\n\n关于**链式法则**：\n\n参考博客：\n[https://zhuanlan.zhihu.com/p/44138371?utm_source=wechat_session](http://)\n\n微积分中的链式法则：两个函数组合起来的复合函数，导数等于里面函数代入外函数值的导数乘以里面函数的导数\n\n\n$$\ny = {f(g(x))}\n$$\n\n第一种：\n$$\n{dy \\over dx} = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}\n$$\n\n"},{"metadata":{"id":"2DDDA40B8BB042A89A731E1408B99FD2","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","outputs":[],"source":"","execution_count":null},{"metadata":{"id":"D102D82E9DB2421C82E07DF2A359DAE4","notebookId":"601a146ea93d4a00153a1d3b","jupyter":{},"tags":[],"slideshow":{"slide_type":"slide"},"trusted":true},"cell_type":"code","outputs":[],"source":"","execution_count":null}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python","nbconvert_exporter":"python","file_extension":".py","version":"3.5.2","pygments_lexer":"ipython3"}},"nbformat":4,"nbformat_minor":0}